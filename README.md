# MedFocusCLIP: Improving Few-Shot Classification in Medical Datasets

Welcome to the official repository for **MedFocusCLIP**! This project combines SAM2 and CLIP to improve few-shot classification in medical images, enabling precise classification with limited data on tasks like X-rays, MRIs, and CT scans.

![Banner](images/medfocusclip_banner.png)

---

## üöÄ Key Features
- **Few-Shot Learning**: Achieve high accuracy with minimal labeled data.
- **Advanced Segmentation**: Leverages SAM2 to pinpoint crucial regions in medical images.
- **State-of-the-Art Performance**: Outperforms existing models across multiple medical datasets.

---

## üß† Architecture

### MedFocusCLIP Framework
MedFocusCLIP combines SAM2's segmentation capabilities with CLIP‚Äôs multimodal vision-language model, utilizing the Vision Transformer (ViT) backbone to enhance few-shot learning.

![MedFocusCLIP Framework](images/medfocusclip_framework.png)

The image demonstrates how SAM2 segments the medical image, while CLIP processes the segmented region, enabling more accurate classification of subtle medical features.

---

## üìä Results

We evaluated MedFocusCLIP on multiple medical datasets, demonstrating significant improvements in accuracy for few-shot learning.

### Performance on COVID-19 Dataset
![Performance Comparison on COVID-19 Dataset](images/covid19_results.png)

| Model             | Accuracy (5% Data) | Accuracy (100% Data) |
|-------------------|--------------------|----------------------|
| ResNet            | 51.52%             | 80.30%               |
| Res2Net           | 43.94%             | 83.33%               |
| VIT               | 65.15%             | 65.15%               |
| Swin-Transformer  | 51.52%             | 86.36%               |
| **MedFocusCLIP**  | **71.15%**         | **93.94%**           |

---

## üî¨ Ablation Studies

### 1. Impact of Using Binary Masks
We evaluated the effect of using binary masks (black and white) versus segmented images. Using binary masks resulted in a significant performance drop, highlighting the importance of texture and color in medical image classification.

![Masked Images from Breast Cancer Dataset](images/breast_cancer_masks.png)

In the figure, the left image is generated by SAM2, and the right image is generated by the SAM Adapter. The SAM2 mask significantly outperforms the SAM Adapter in terms of classification accuracy.

### 2. Using SAM Adapter vs SAM2
We replaced SAM2 with the SAM Adapter to see its effect on performance. The results showed a marginal decrease in accuracy, indicating that SAM2's sophisticated segmentation is better suited for medical imagery.

---

## üìÅ Datasets
MedFocusCLIP has been evaluated on the following datasets:
- [COVID-19 Dataset](https://example.com)
- [Lung Disease Dataset](https://example.com)
- [Brain Tumor Dataset](https://example.com)
- [Breast Cancer Dataset](https://example.com)

---

## ‚öôÔ∏è Installation

1. Clone this repository:

   ```bash
   git clone https://github.com/yourusername/MedFocusCLIP.git
   cd MedFocusCLIP
